{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane detection based on Hough transform\n",
    "### Author: Xia Shang\n",
    "### Udacity self-drive car project \\# 1\n",
    "### Keywords: GaussianBlur, Canny transform, Masked region, Hough transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "#import imageio\n",
    "#imageio.plugins.ffmpeg.download()\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_lines(image):\n",
    "    # convert to YUV color scheme\n",
    "    yuv_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "    # convert the image to grayscale\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    kernel_size = 7\n",
    "    blur_gray = cv2.GaussianBlur(yuv_image,(kernel_size, kernel_size),0)\n",
    "    # Define parameters for Canny\n",
    "    low_threshold = 40\n",
    "    high_threshold = 80\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    # create a masked edges image using cv2.fillPoly()\n",
    "    mask = np.zeros_like(edges)   \n",
    "    ignore_mask_color = 255   \n",
    "    mask = np.zeros_like(edges)\n",
    "    imshape = image.shape\n",
    "    vertices = np.array([[(int(imshape[1]*0.52),int(imshape[0]*0.58)),(int(imshape[1]*0.1), int(imshape[0])), (int(imshape[1]*0.9), int(imshape[0]*0.98)), (int(imshape[1]*0.55),int(imshape[0]*0.6))]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, vertices, 255)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "    # Define the Hough transform parameters\n",
    "    # Make a blank the same size as our image to draw on\n",
    "    rho = 0.8 # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180 # angular resolution in radians of the Hough grid\n",
    "    threshold = 25     # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 50 #minimum number of pixels making up a line\n",
    "    max_line_gap = 200    # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "    # Run Hough on edge detected image\n",
    "    # Output \"lines\" is an array containing endpoints of detected line segments\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]),\n",
    "                            min_line_length, max_line_gap)   \n",
    "    return lines, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separate_lanes (lines):\n",
    "    # separate the left and right lanes\n",
    "    left_lane = []\n",
    "    right_lane = []\n",
    "    for x1,y1,x2,y2 in lines[:,0]:\n",
    "        if abs(y1-y2)>20: # filter out the horizontal lines\n",
    "            k = (float(y2) - y1) / (x2 - x1)\n",
    "            if k > 0:\n",
    "                right_lane.append([x1,y1,x2,y2,k])\n",
    "            else:\n",
    "                left_lane.append([x1,y1,x2,y2,k])\n",
    "    return np.array(left_lane), np.array(right_lane) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_lanes(lane, minimum, maximum):\n",
    "    # filter the lanes based on the slope\n",
    "    lane = lane[ (maximum>lane[:,4]) & (lane[:,4]>minimum) ]\n",
    "    return lane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_lane(points):\n",
    "    # use linear regression to get one line for each lane\n",
    "    points = points[:,0:4]\n",
    "    points = points.reshape(points.shape[0]*2,2)\n",
    "    m,b = np.polyfit(points[:,0], points[:,1], 1)\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_line(lines, y_left, y_right, line_image):\n",
    "    left_lane, right_lane = separate_lanes (lines)\n",
    "    left_lane = filter_lanes(left_lane, -0.9, -0.6)\n",
    "    right_lane = filter_lanes(right_lane, 0.45, 0.75)\n",
    "    m_left, b_left = combine_lane(left_lane)\n",
    "    m_right, b_right = combine_lane(right_lane)\n",
    "    x_left = [int((xx - b_left)/m_left) for xx in y_left]\n",
    "    x_right = [int((xx - b_right)/m_right) for xx in y_right]\n",
    "    cv2.line(line_image,(x_left[0],y_left[0]),(x_left[1],y_left[1]),(0,0,255),10)\n",
    "    cv2.line(line_image,(x_right[0],y_right[0]),(x_right[1],y_right[1]),(0,0,255),10)\n",
    "    return line_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embed_image(image, embed_image, x_offset, y_offset):\n",
    "    image[y_offset:y_offset+embed_image.shape[0], x_offset:x_offset+embed_image.shape[1]] = embed_image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_lanes(image):\n",
    "    imshape = image.shape\n",
    "    lines, edges = generate_lines(image)\n",
    "    line_image = np.copy(image)*0 # creating a blank to draw lines on\n",
    "    y_left = [int(imshape[0]*0.95), int(imshape[0]*0.62)] # y_coordinates of left lane\n",
    "    y_right = [int(imshape[0]*0.95), int(imshape[0]*0.62)] # x_coordinates of right lane\n",
    "    line_image = draw_line(lines, y_left, y_right, line_image)\n",
    "    small_edges = cv2.resize(edges, (0,0), fx = 0.2, fy = 0.2)\n",
    "    small_edges = np.dstack((small_edges, small_edges, small_edges))\n",
    "    small_line = cv2.resize(line_image, (0,0), fx = 0.2, fy = 0.2)\n",
    "    x_offset_edge = 50\n",
    "    y_offset_edge = 30\n",
    "    x_offset_line = x_offset_edge + small_edges.shape[1] + 10\n",
    "    y_offset_line = y_offset_edge\n",
    "    image = embed_image(image, small_edges, x_offset_edge, y_offset_edge)\n",
    "    image = embed_image(image, small_line, x_offset_line, y_offset_line)\n",
    "    lines_edges = cv2.addWeighted(image, 0.8, line_image, 1, 0)\n",
    "    cv2.putText(lines_edges,\"Edges\", (x_offset_edge + 90, y_offset_edge + small_edges.shape[0] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    cv2.putText(lines_edges,\"Lanes\", (x_offset_line + 90, y_offset_edge + small_edges.shape[0] + 30), cv2.FONT_HERSHEY_SIMPLEX, 1,(255,255,255),2)\n",
    "    return lines_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_clip = VideoFileClip(\"test.mp4\").subclip(0,-1)\n",
    "new_clip = test_clip.fl_image(add_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_output.mp4\n",
      "[MoviePy] Writing video test_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [00:15<00:00, 11.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_output.mp4 \n",
      "\n",
      "CPU times: user 12.4 s, sys: 2.33 s, total: 14.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "#new_clip.ipython_display(width = 600) # examine the lanes \n",
    "new_clip_output = 'test_output.mp4'\n",
    "%time new_clip.write_videofile(new_clip_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the movie before processing\n",
    "video = io.open('test.mp4', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "<video width=\"600\" height=\"500\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "</video>'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# see the movie after processing\n",
    "video = io.open('test_output.mp4', 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "<video width=\"600\" height=\"500\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "</video>'''.format(encoded.decode('ascii')))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
